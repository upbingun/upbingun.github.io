---
title: ITä¹‹å®¶æ–°é—»APIä»¥åŠå®æˆ˜
tags: [API]
categories: [API]
date: 2025-10-25
description: ä½¿ç”¨ITä¹‹å®¶çš„APIå¹¶åˆ©ç”¨Pythonè¿›è¡Œæ–°é—»æ‰“å°ã€‚
articleGPT: è¿™æ˜¯ä¸€ç¯‡æœ‰å…³ITä¹‹å®¶æ–°é—»è·å–æ–‡ç« ï¼Œæ—¨åœ¨äºä»‹ç»ITä¹‹å®¶çš„API
references:
  - title: vitepress-theme-curve
    url: https://github.com/imsyy/vitepress-theme-curve
---

# ITä¹‹å®¶æ–°é—»APIä»¥åŠå®æˆ˜
æ¬¢è¿æ¥åˆ°upbingunçš„åšå®¢ã€‚<br>
æˆ‘ä»¬å°†ä¼šåœ¨æ­¤ä»‹ç»ITä¹‹å®¶çš„ä¸€äº›APIï¼Œä»¥åŠå¦‚ä½•ç”¨å®ƒåˆ¶ä½œä¸€ä¸ªåº”ç”¨ç¨‹åºã€‚<br>
:::info
è€ƒè™‘åˆ°ç§ç§å› ç´ ï¼Œæœ¬æ¬¡ç¤ºä¾‹ä½¿ç”¨Pythonã€‚å› ä¸ºæˆ‘å¹¶ä¸ä¸“ä¸šPythonæ‰€ä»¥è¿™äº›ä»£ç æ˜¯ç”±AIç”Ÿæˆçš„ã€‚
:::

## èµ·å› 
æˆ‘ä¹‹å‰æäº†ä¸ªNOKIA 8110ç”¨æ¥æ‰“ç”µè¯ï¼ˆHMDæ—¶ä»£çš„æ‰‹æœºï¼Œä½¿ç”¨KaiOSï¼Œåæ¥åœ¨[è¯ºäºšæ–¹èˆŸå·](https://www.dospy.wang/)çœ‹åˆ°æœ‰ä¸€äº›ææœºæ–‡ç« è£…åº”ç”¨è¿›å»ï¼Œäºæ˜¯çœ‹åˆ°æœ‰ä¸ªITä¹‹å®¶çš„KaiOSç‰ˆï¼ˆæ–‡ç« ï¼š[åŸæ–‡é“¾æ¥](https://www.dospy.wang/thread-13183-1-1.html)ï¼‰ã€‚é™¤äº†æŒ‰é”®ç²˜è¿å›å¯¼è‡´æœ‰æ—¶å€™ä¸å°å¿ƒé€€å‡ºå…¶ä»–éƒ½è¿˜æ˜¯è›®ä¸é”™çš„ã€‚æ­£å¥½ä»¥æ­¤æœºä¼šè®¤è¯†åˆ°äº†ITä¹‹å®¶è¿™ä¸ªæ–°é—»ç½‘ç«™ï¼Œä¸ªäººè®¤ä¸ºæ–°é—»è¿˜æ˜¯è›®ä¸é”™çš„ã€‚<br>
æ—¢ç„¶éƒ½èƒ½åœ¨KaiOSä¸Šé€‚é…ï¼Œé‚£è‚¯å®šæœ‰æ¯”è¾ƒç®€æ˜“çš„APIç”¨äºè·å–æ–°é—»çš„ã€‚

## APIçš„æ”¶é›†
### åœ¨ç½‘ä¸Šçš„æœå¯»
åœ¨Bing/Googleä¸Šæœç´¢`ITä¹‹å®¶API`å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªè¾ƒä¸ºæœ‰ç”¨çš„GitHubé¡¹ç›®ï¼Œä¸º[F-loatçš„ithome-lite](https://github.com/F-loat/ithome-lite)ï¼Œä½œè€…åœ¨`readme.md`ä¸­å†™é“ï¼š

>* æ–°é—»åˆ—è¡¨ https://api.ithome.com/json/newslist/news?r=0
>* æ–‡ç« è¯¦æƒ… https://api.ithome.com/xml/newscontent/350/412.xml
>* ç›¸å…³æ–‡ç«  https://api.ithome.com/json/tags/0350/350362.json
>* æœ€çƒ­è¯„è®º https://dyn.ithome.com/json/hotcommentlist/350/87a8e5b144d81938.json
>* è¯„è®ºåˆ—è¡¨ https://dyn.ithome.com/json/commentlist/350/87a8e5b144d81938.json
>* è¯„è®ºè¯¦æƒ… https://dyn.ithome.com/json/commentcontent/d739ee8f2ceb0a27.json
>* è½®æ’­æ–°é—» https://api.ithome.com/xml/slide/slide.xml
>* åœˆå­åˆ—è¡¨ https://apiquan.ithome.com/api/post?categoryid=0&type=0&orderTime=&visistCount&pageLength
>* åœˆå­è¯¦æƒ… https://apiquan.ithome.com/api/post/236076
>* åœˆå­è¯„è®º https://apiquan.ithome.com/api/reply?postid=236076&replyidlessthan=3241294

ç»è¿‡äº†æˆ‘çš„æ•´ç†ï¼Œå¤§æ¦‚å°±æ˜¯ç±»ä¼¼äº`350`è¿™ç§æ˜¯å‰3ä½çš„`newsid`ï¼Œ`412`å°±æ˜¯åä¸‰ä½çš„ã€‚ä½†æ˜¯è¯„è®ºä¸­çš„`87a8e5b144d81938`è¿™ç§ç»è¿‡æˆ‘çš„æŸ¥æ‰¾å‘ç°æ˜¯åµŒåœ¨HTMLå†…çš„ï¼ˆç±»ä¼¼äº`https://www.ithome.com/0/892/239.htm`è¿™ç§çš„ã€‚åœ¨æˆ‘æ‰€è§‚å¯Ÿçš„ç½‘é¡µæºä»£ç ä¸­ï¼ˆå¯èƒ½ä¼šè¿‡ä¸€é˜µè¢«ITä¹‹å®¶åˆ æ‰ï¼‰æœ‰
```html
<div id="post_comm" data-id="7afc9486b51b2e5a" data-nid="892239"></div>
```
è¿™è¯´æ˜æŒ‰ç…§æˆ‘çš„æ€è·¯å¿…é¡»è¦è·å–è¿™ä¸ªç½‘é¡µæœ¬èº«æ‰èƒ½å¾—åˆ°è¿™ä¸ª`data-id`ã€‚è¿™æœªå…æˆæœ¬æœ‰ç‚¹é«˜ã€‚æˆ‘åœ¨è¿™é‡Œä¸åšæ¼”ç¤ºäº†ï¼Œæˆ‘è®¤ä¸ºæ€»ä½“æ€è·¯å¯ä»¥è·å–æºä»£ç å¹¶æå–è¿™ä¸€å­—æ®µç„¶åæ‰’å‡ºæ¥ã€‚æˆ‘åªåœ¨è¿™é‡Œæ¼”ç¤ºè·å–æ–‡ç« å†…å®¹äº†ã€‚<br>
ä½†æ˜¯æˆ‘ç›´æ¥è¯·æ±‚æ–°é—»åˆ—è¡¨çš„æ—¶å€™ï¼Œå‘ç°åªæœ‰ç¬¬ä¸€é¡µï¼Œæ²¡æœ‰ä½™ä¸‹çš„é‚£å‡ é¡µï¼Œ`r`çš„å€¼è²Œä¼¼ä¸å½±å“é¡µæ•°ã€‚
### æ–°é—»åˆ—è¡¨APIçš„è·å–
æˆ‘å»ç½‘é¡µä¸Šç›‘æµ‹ç½‘ç»œæ´»åŠ¨çœ‹çœ‹ç½‘é¡µæ˜¯æ€ä¹ˆè·å–æ–°é—»åˆ—è¡¨çš„ã€‚åœ¨[m.ithome.com](https://m.ithome.com/)ä¸ŠæŠ“åŒ…ï¼ŒæŠ“åˆ°`
https://m.ithome.com/api/news/newslistpageget?Tag=&ot=1761353613000&page=0&hitCountAuthority=false`è¿™ä¸ªåˆ—è¡¨ï¼Œå†…å®¹ä¸ºï¼š
```json
{Success: 1,â€¦}
Result: [{newsid: 892244, title: "HMD é¦–æ¬¾æ¨¡å—åŒ–æ‰‹æœºç»§ä»»è€… Fusion 2 æ›å…‰ï¼šå‡çº§éªé¾™ 6s Gen 4 å¤„ç†å™¨ã€æ¢ç”¨ FHD+ 120Hz é¢æ¿", v: null,â€¦},â€¦]
0: {newsid: 892244, title: "HMD é¦–æ¬¾æ¨¡å—åŒ–æ‰‹æœºç»§ä»»è€… Fusion 2 æ›å…‰ï¼šå‡çº§éªé¾™ 6s Gen 4 å¤„ç†å™¨ã€æ¢ç”¨ FHD+ 120Hz é¢æ¿", v: null,â€¦}
1: {newsid: 892243, title: "é‡Œç¨‹ç¢‘ï¼šé¦–ä¸ª SDK å‘å¸ƒï¼Œå¼€å‘è€…èƒ½ç”¨è‹¹æœ Swift è¯­è¨€å¼€å‘å®‰å“ App", v: null,â€¦}
2:
More...
24: {newsid: 892223, title: "ä¹°å®¶ç½‘è´­è‹¹æœæ‰‹æœºä»…é€€æ¬¾ä¸é€€è´§é­å•†å®¶ç»´æƒï¼Œæ³•å®˜è°ƒè§£åæ”¯ä»˜è´§æ¬¾", v: "100",â€¦}
Success: 1
```
å…¶ä¸­`page`åœ¨ç½‘é¡µç«¯æ¥ä¸‹æ¥çš„è·å–é“¾æ¥æ˜¯æ²¡æœ‰å˜åŠ¨çš„ï¼Œåªæœ‰`ot`å˜åŠ¨ã€‚å…¶ä¸­`ot`æ˜¯æ—¶é—´æˆ³ã€‚`ot`å‚æ•°å®é™…ä¸Šæ˜¯ä¸Šä¸€é¡µæœ€åä¸€æ¡æ–°é—»çš„ `orderdate` æ—¶é—´æˆ³ã€‚ï¼ˆ_DeepSeek_ æŒ‡å‡ºã€‚ï¼‰æ‰€ä»¥æ¥ä¸‹æ¥éƒ½å¥½åŠäº†ã€‚<br>
å› æ­¤æ„é€ é“¾æ¥å¤§è‡´ä¸ºï¼š
```url
https://m.ithome.com/api/news/newslistpageget?Tag=&ot={æ—¶é—´æˆ³}&page=0&hitCountAuthority=false
```
### æ€»ç»“
å› æ­¤æˆ‘ä»¬æ•´ç†å‡ºæ¥çš„å¯ç”¨APIæœ‰
> * è·å–æ–°é—»å†…å®¹ https://api.ithome.com/xml/newscontent/å‰ä¸‰ä½/åä¸‰ä½.xml
> * è·å–æ–‡ç« åˆ—è¡¨ https://m.ithome.com/api/news/newslistpageget?Tag=&ot={æ—¶é—´æˆ³}&page=0&hitCountAuthority=false

### APIè¯·æ±‚è¿”å›å†…å®¹ï¼š
ä»¥ä¸‹ä¸ºæˆ‘åœ¨2025-10-25 11:34è¯·æ±‚`https://m.ithome.com/api/news/newslistpageget?Tag=&ot=1761354775000&page=0&hitCountAuthority=false`è¿”å›çš„å†…å®¹
```json
{"Success":1,"Result":[
    {"newsid":892248,"title":"RAID 1 é˜µåˆ— Win10 è®¾å¤‡å‡çº§ Win11â€œå˜ç –â€ï¼Œåˆæ­¥é”å®šè‹±ç‰¹å°” RST é©±åŠ¨æƒ¹ç¥¸","v":null,"orderdate":"2025-10-25T09:12:52.55","postdate":"2025-10-25T09:12:52.55","description":"ç§‘æŠ€åª’ä½“ borncity æ˜¨æ—¥ï¼ˆ10 æœˆ 24 æ—¥ï¼‰å‘å¸ƒåšæ–‡ï¼ŒæŠ¥é“ç§°æœ‰ç”¨æˆ·åé¦ˆï¼Œåœ¨é…ç½®äº† RAID 1 é˜µåˆ—çš„æƒ æ™®ï¼ˆHPï¼‰ç”µè„‘ä¸Šï¼Œå¦‚æœä» Windows 10 å‡çº§è‡³ Windows 11ï¼Œç³»ç»Ÿä¼šé­é‡è‡´å‘½çš„å¯åŠ¨å¤±è´¥é—®é¢˜ã€‚","image":"https://img.ithome.com/newsuploadfiles/thumbnail/2025/10/892248_240.jpg?r=1761354772550","slink":null,"hitcount":0,"commentcount":28,"hidecount":false,"subtitle":null,"cid":183,"url":"/0/892/248.htm","live":0,"lapinid":null,"forbidcomment":false,"imagelist":null,"c":null,"client":null,"isad":false,"sid":0,"PostDateStr":"09:12","HitCountStr":null,"WapNewsUrl":"https://m.ithome.com/html/892248.htm","NewsTips":[],"IsChineseMainland":true},
    {"newsid":892247,"title":"ä¿æ—¶æ·ä»Šå¹´å‰ä¸‰å­£åº¦è¥ä¸šåˆ©æ¶¦ 4000 ä¸‡æ¬§å…ƒæš´è·Œ 99%ï¼Œä¸‰æ¬¾ç‡ƒæ²¹è½¦å‹å³å°†åœäº§","v":null,"orderdate":"2025-10-25T09:10:37.187","postdate":"2025-10-25T09:10:37.187","description":"å…¬å¸è§£é‡Šç§°ï¼Œåˆ©æ¶¦å¤§å¹…ä¸‹é™çš„åŸå› åŒ…æ‹¬äº§å“æˆ˜ç•¥è°ƒæ•´ã€ä¸­å›½å¸‚åœºçš„ä¸åˆ©å½¢åŠ¿ï¼Œä»¥åŠç”µæ± ç›¸å…³çš„ä¸€æ¬¡æ€§è´¹ç”¨ã€‚æ­¤å¤–ï¼Œå…³ç¨ä¹Ÿæ˜¯ä¸€å¤§å› ç´ ï¼Œé¢„è®¡ä»Šå¹´å…³ç¨æ”¯å‡ºå°†è¾¾åˆ° 7 äº¿æ¬§å…ƒã€‚","image":"https://img.ithome.com/newsuploadfiles/thumbnail/2025/10/892247_240.jpg?r=1761354637187","slink":null,"hitcount":0,"commentcount":70,"hidecount":false,"subtitle":null,"cid":192,"url":"/0/892/247.htm","live":0,"lapinid":null,"forbidcomment":false,"imagelist":null,"c":null,"client":null,"isad":false,"sid":0,"PostDateStr":"09:10","HitCountStr":null,"WapNewsUrl":"https://m.ithome.com/html/892247.htm","NewsTips":[],"IsChineseMainland":true}...
]}
```
| å­—æ®µå                                              | å«ä¹‰                                                                                          |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------- |
| `newsid`                                         | æ–‡ç«  IDï¼ˆå¦‚ `892248`ï¼‰                                                                           |
| `title`                                          | æ–°é—»æ ‡é¢˜                                                                                        |
| `description`                                    | æ‘˜è¦æˆ–å¯¼è¯­                                                                                       |
| `image`                                          | ç¼©ç•¥å›¾åœ°å€                                                                                       |
| `url`                                            | PC ç½‘é¡µç›¸å¯¹è·¯å¾„ï¼ˆå¦‚ `/0/892/248.htm`ï¼‰                                                               |
| `WapNewsUrl`                                     | æ‰‹æœºç‰ˆæ–°é—»å®Œæ•´é“¾æ¥ï¼ˆä¾‹å¦‚ï¼š[https://m.ithome.com/html/892248.htmï¼‰](https://m.ithome.com/html/892248.htmï¼‰) |
| `commentcount`                                   | è¯„è®ºæ•°                                                                                         |
| `orderdate` / `postdate`                         | å‘å¸ƒæ—¶é—´ï¼ˆISO æ—¶é—´æ ¼å¼ï¼‰                                                                              |
| `cid`                                            | åˆ†ç±» IDï¼ˆä¾‹å¦‚ 183 å¯èƒ½æ˜¯ Windows / ç³»ç»Ÿç±»æ–°é—»ï¼‰                                                             |
| `NewsTips`                                       | æ ‡ç­¾ä¿¡æ¯ï¼Œå¦‚ã€Œå¹¿å‘Šã€ã€Œè§†é¢‘ã€ç­‰                                                                             |
| `IsChineseMainland`                              | æ˜¯å¦ä¸­å›½å¤§é™†æ–°é—»                                                                                    |
| `title` / `description` / `image` ç»„åˆå¯ç›´æ¥ç”¨äºå±•ç¤ºæ–°é—»å¡ç‰‡ã€‚ |                                                                                             |

ä»¥ä¸‹ä¸ºæˆ‘åœ¨2025-10-25 11:43è¯·æ±‚`https://api.ithome.com/xml/newscontent/892/248.xml`å¾—åˆ°çš„ï¼š
```xml
<rss version="2.0">
<channel><item><newsid>892248</newsid>
<title>
<![CDATA[ RAID 1 é˜µåˆ— Win10 è®¾å¤‡å‡çº§ Win11â€œå˜ç –â€ï¼Œåˆæ­¥é”å®šè‹±ç‰¹å°” RST é©±åŠ¨æƒ¹ç¥¸ ]]>
</title>
<c/>
<v>000</v>
<url>/0/892/248.htm</url>
<image>https://img.ithome.com/newsuploadfiles/thumbnail/2025/10/892248_240.jpg</image>
<description>
<![CDATA[ ç§‘æŠ€åª’ä½“ borncity ... å¤±è´¥é—®é¢˜ã€‚ ]]>
</description>
<newssource>ITä¹‹å®¶</newssource>
<newsauthor>æ•…æ¸Š</newsauthor>
<detail>
<![CDATA[ <p data-vmark="65e2">ITä¹‹å®¶ 10 æœˆ 25 æ—¥æ¶ˆæ¯ï¼Œ ... ï¼ˆæ–°é—»å†…å®¹ç•¥ï¼‰ ...ä»è€Œå¼•å‘è‡´å‘½çš„ç£ç›˜è¯»å–é”™è¯¯ã€‚</p> ]]>
</detail>
<postdate>2025/10/25 9:12:52</postdate>
<hitcount>1421</hitcount>
<commentcount>0</commentcount>
<forbidcomment>false</forbidcomment>
<z>æ•…æ¸Š</z>
</item></channel></rss>
```
## å®æˆ˜
æˆ‘åšè¿™ä¸ªæ˜¯å› ä¸ºæƒ³æ‹¿ä¸€äº›æ–°é—»å»å­¦æ ¡çœ‹ï¼Œä¸‹é¢çš„pythonè„šæœ¬å¯ä»¥è‡ªåŠ¨è·å–æ–°é—»å†…å®¹å¹¶ç”Ÿæˆä¸€ä»½Microsoft Word(docx)æ–‡æ¡£ç”¨æ¥æ‰“å°ã€‚æ­£æ–‡å­—ä½“ä¸ºæ–¹æ­£ä¹¦å®‹ï¼Œæ ‡é¢˜ä¸ºMicrosoft Yahei UI Lightã€‚<br>
:::info
ä»¥ä¸‹å†…å®¹ç”±DeepSeekç”Ÿæˆ
:::
```python
import requests
import json
from datetime import datetime
import time
import random
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
import re
import html
import logging
from typing import Optional, Dict, List

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ithome_printer.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ITHomePrinterWithStyles:
    def __init__(self):
        self.base_url = "https://m.ithome.com/api/news/newslistpageget"
        self.news_content_base_url = "https://api.ithome.com/xml/newscontent"
        self.document = Document()
        
        # é‡è¯•é…ç½®
        self.max_retries = 5
        self.retry_delay = 2
        self.max_delay = 60
        
        # è¯·æ±‚é…ç½®
        self.request_timeout = 15
        self.batch_size = 5
        
        # User-Agentè½®æ¢
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15"
        ]
        
        # å¤±è´¥é˜Ÿåˆ—
        self.failed_news_ids = []
        
        self.setup_styles()
    
    def setup_styles(self):
        """è®¾ç½®æ–‡æ¡£æ ·å¼"""
        # è®¾ç½®æ­£æ–‡æ ·å¼
        style = self.document.styles['Normal']
        font = style.font
        font.name = 'Times New Roman'
        font.size = Pt(9)
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        font.element.rPr.rFonts.set(qn('w:eastAsia'), 'æ–¹æ­£ä¹¦å®‹_GB18030')
        
        # è®¾ç½®æ®µè½æ ¼å¼
        paragraph_format = style.paragraph_format
        paragraph_format.line_spacing = Pt(9)  # å›ºå®šå€¼9ç£…
        paragraph_format.space_before = Pt(0)
        paragraph_format.space_after = Pt(0)
        paragraph_format.widow_control = True  # å­¤è¡Œæ§åˆ¶
        
        # åˆ›å»ºæ ‡é¢˜æ ·å¼
        try:
            title_style = self.document.styles.add_style('ITHomeTitle', 1)
        except:
            title_style = self.document.styles['Heading 1']
        
        title_font = title_style.font
        title_font.name = 'Microsoft YaHei UI Light'
        title_font.size = Pt(11)
        title_font.color.rgb = None  # æ–‡å­—1é¢œè‰²ï¼ˆé»‘è‰²ï¼‰
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        title_font.element.rPr.rFonts.set(qn('w:eastAsia'), 'Microsoft YaHei UI Light')
        
        title_paragraph_format = title_style.paragraph_format
        title_paragraph_format.line_spacing = Pt(13)  # å›ºå®šå€¼13ç£…
        title_paragraph_format.space_before = Pt(0)
        title_paragraph_format.space_after = Pt(0)
        title_paragraph_format.keep_with_next = True  # ä¸ä¸‹æ®µåŒé¡µ
        title_paragraph_format.keep_together = True   # æ®µä¸­ä¸åˆ†é¡µ
    
    def get_random_user_agent(self):
        """è·å–éšæœºUser-Agent"""
        return random.choice(self.user_agents)
    
    def create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': self.get_random_user_agent(),
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://m.ithome.com/',
            'Origin': 'https://m.ithome.com'
        })
        return session
    
    def exponential_backoff(self, retry_count):
        """æŒ‡æ•°é€€é¿ç®—æ³•"""
        delay = min(self.retry_delay * (2 ** retry_count), self.max_delay)
        delay += random.uniform(0, 1)
        return delay
    
    def safe_request(self, url, method='GET', params=None, session=None, retry_count=0):
        """å®‰å…¨çš„è¯·æ±‚å‡½æ•°ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        if retry_count >= self.max_retries:
            logger.error(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {url}")
            return None
        
        if session is None:
            session = self.create_session()
        
        try:
            if method.upper() == 'GET':
                response = session.get(url, params=params, timeout=self.request_timeout)
            else:
                response = session.get(url, params=params, timeout=self.request_timeout)
            
            if response.status_code == 200:
                logger.info(f"è¯·æ±‚æˆåŠŸ: {url}")
                return response
            elif response.status_code == 403:
                logger.warning(f"é‡åˆ°403é™åˆ¶ï¼Œç¬¬{retry_count + 1}æ¬¡é‡è¯•: {url}")
                session.headers['User-Agent'] = self.get_random_user_agent()
                delay = self.exponential_backoff(retry_count)
                logger.info(f"ç­‰å¾… {delay:.2f} ç§’åé‡è¯•...")
                time.sleep(delay)
                return self.safe_request(url, method, params, session, retry_count + 1)
            elif response.status_code == 429:
                logger.warning(f"è¯·æ±‚è¿‡äºé¢‘ç¹(429)ï¼Œç¬¬{retry_count + 1}æ¬¡é‡è¯•: {url}")
                delay = self.exponential_backoff(retry_count) * 2
                logger.info(f"ç­‰å¾… {delay:.2f} ç§’åé‡è¯•...")
                time.sleep(delay)
                return self.safe_request(url, method, params, session, retry_count + 1)
            else:
                logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç  {response.status_code}: {url}")
                return None
                
        except requests.exceptions.Timeout:
            logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼Œç¬¬{retry_count + 1}æ¬¡é‡è¯•: {url}")
            delay = self.exponential_backoff(retry_count)
            time.sleep(delay)
            return self.safe_request(url, method, params, session, retry_count + 1)
            
        except requests.exceptions.ConnectionError:
            logger.warning(f"è¿æ¥é”™è¯¯ï¼Œç¬¬{retry_count + 1}æ¬¡é‡è¯•: {url}")
            delay = self.exponential_backoff(retry_count)
            time.sleep(delay)
            return self.safe_request(url, method, params, session, retry_count + 1)
            
        except Exception as e:
            logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}, URL: {url}")
            return None
    
    def datetime_to_timestamp(self, dt_str):
        """å°†æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰"""
        try:
            if 'T' in dt_str:
                dt_obj = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
            else:
                dt_obj = datetime.strptime(dt_str, "%Y-%m-%d %H:%M:%S")
            return int(dt_obj.timestamp() * 1000)
        except Exception as e:
            logger.warning(f"æ—¶é—´è½¬æ¢é”™è¯¯: {e}, è¾“å…¥: {dt_str}")
            return int(time.time() * 1000)
    
    def get_news_list_page(self, ot=None, page=0):
        """è·å–å•é¡µæ–°é—»åˆ—è¡¨"""
        params = {
            'Tag': '',
            'page': page,
            'hitCountAuthority': 'false'
        }
        
        if ot:
            params['ot'] = ot
            
        url = self.base_url
        response = self.safe_request(url, params=params)
        
        if response:
            try:
                data = response.json()
                if data.get('Success') == 1:
                    news_list = data.get('Result', [])
                    logger.info(f"è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
                    return news_list
                else:
                    logger.error(f"APIè¿”å›å¤±è´¥: {data}")
            except json.JSONDecodeError:
                logger.error("JSONè§£æå¤±è´¥")
        
        return []
    
    def get_multiple_pages(self, total_articles=50, initial_ot=None):
        """è·å–å¤šé¡µæ–°é—»"""
        all_news = []
        current_ot = initial_ot
        page = 0
        
        while len(all_news) < total_articles:
            logger.info(f"è·å–ç¬¬ {page + 1} é¡µæ–°é—»...")
            page_news = self.get_news_list_page(current_ot, page)
            
            if not page_news:
                logger.info("æ²¡æœ‰æ›´å¤šæ–°é—»äº†")
                break
            
            # è¿‡æ»¤å¹¿å‘Š
            valid_news = []
            for news in page_news:
                is_ad = False
                news_tips = news.get('NewsTips', [])
                for tip in news_tips:
                    if tip.get('TipName') == 'å¹¿å‘Š':
                        is_ad = True
                        break
                
                if not is_ad and news.get('title'):
                    valid_news.append(news)
            
            all_news.extend(valid_news)
            logger.info(f"å½“å‰æ€»è®¡: {len(all_news)} æ¡æœ‰æ•ˆæ–°é—»")
            
            # æ›´æ–°otå‚æ•°
            if valid_news:
                last_news = valid_news[-1]
                last_orderdate = last_news.get('orderdate')
                if last_orderdate:
                    current_ot = self.datetime_to_timestamp(last_orderdate)
                    logger.info(f"ä¸‹ä¸€é¡µotå‚æ•°: {current_ot}")
            
            page += 1
            time.sleep(1)
            
            if page >= 20:
                logger.warning("è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶")
                break
        
        return all_news[:total_articles]
    
    def clean_html(self, text):
        """æ¸…ç†HTML"""
        if not text:
            return ""
        text = html.unescape(text)
        clean = re.compile('<.*?>')
        text = re.sub(clean, '', text)
        text = text.replace('<![CDATA[', '').replace(']]>', '')
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    def get_news_content_with_retry(self, newsid):
        """å¸¦é‡è¯•æœºåˆ¶çš„è·å–æ–°é—»å†…å®¹"""
        newsid_str = str(newsid)
        prefix = newsid_str[:3]
        suffix = newsid_str[3:]
        url = f"{self.news_content_base_url}/{prefix}/{suffix}.xml"
        
        response = self.safe_request(url)
        
        if response:
            try:
                content = response.text
                title_match = re.search(r'<title><!\[CDATA\[(.*?)\]\]></title>', content)
                detail_match = re.search(r'<detail><!\[CDATA\[(.*?)\]\]></detail>', content)
                author_match = re.search(r'<newsauthor>(.*?)</newsauthor>', content)
                postdate_match = re.search(r'<postdate>(.*?)</postdate>', content)
                
                return {
                    'title': self.clean_html(title_match.group(1)) if title_match else "",
                    'content': self.clean_html(detail_match.group(1)) if detail_match else "",
                    'author': self.clean_html(author_match.group(1)) if author_match else "",
                    'postdate': self.clean_html(postdate_match.group(1)) if postdate_match else ""
                }
            except Exception as e:
                logger.error(f"è§£æå†…å®¹å¤±è´¥ (ID: {newsid}): {e}")
        
        return None
    
    def process_news_batch(self, news_batch):
        """å¤„ç†ä¸€æ‰¹æ–°é—»"""
        results = []
        for news in news_batch:
            newsid = news.get('newsid')
            title = news.get('title', '')
            
            logger.info(f"å¤„ç†æ–‡ç« : {title[:50]}...")
            
            content_data = self.get_news_content_with_retry(newsid)
            
            if content_data and content_data.get('content'):
                results.append((news, content_data))
            else:
                self.failed_news_ids.append(newsid)
                logger.warning(f"æ–‡ç« å†…å®¹è·å–å¤±è´¥ï¼Œå·²åŠ å…¥é‡è¯•é˜Ÿåˆ—: {title[:50]}...")
            
            time.sleep(random.uniform(0.5, 1.5))
        
        return results
    
    def retry_failed_news(self):
        """é‡è¯•å¤±è´¥çš„æ–°é—»"""
        if not self.failed_news_ids:
            return []
        
        logger.info(f"å¼€å§‹é‡è¯• {len(self.failed_news_ids)} ç¯‡å¤±è´¥çš„æ–‡ç« ...")
        
        retry_results = []
        still_failed = []
        
        for newsid in self.failed_news_ids[:]:
            content_data = self.get_news_content_with_retry(newsid)
            
            if content_data and content_data.get('content'):
                retry_results.append(({'newsid': newsid}, content_data))
                self.failed_news_ids.remove(newsid)
                logger.info(f"é‡è¯•æˆåŠŸ: {newsid}")
            else:
                still_failed.append(newsid)
                logger.warning(f"é‡è¯•ä»ç„¶å¤±è´¥: {newsid}")
            
            time.sleep(random.uniform(1, 2))
        
        self.failed_news_ids = still_failed
        
        return retry_results
    
    def format_content(self, content):
        """æ ¼å¼åŒ–å†…å®¹"""
        if not content:
            return ""
        
        paragraphs = []
        current_para = []
        
        sentences = [s.strip() for s in content.split('ã€‚') if s.strip()]
        
        for i, sentence in enumerate(sentences):
            current_para.append(sentence)
            
            if len(current_para) >= 2 or i == len(sentences) - 1:
                paragraphs.append('ã€‚'.join(current_para) + 'ã€‚')
                current_para = []
        
        return '\n\n'.join(paragraphs)
    
    def add_news_to_document(self, news_data, content_data, is_first_news=False):
        """æ·»åŠ æ–°é—»åˆ°æ–‡æ¡£"""
        try:
            title = news_data.get('title', '')
            description = news_data.get('description', '')
            orderdate = news_data.get('orderdate', '')
            
            if content_data and content_data.get('content'):
                full_content = content_data['content']
                author = content_data.get('author', '')
                postdate = content_data.get('postdate', '')
            else:
                full_content = description if description else "æš‚æ— è¯¦ç»†å†…å®¹"
                author = ""
                postdate = orderdate
            
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¡æ–°é—»ï¼Œå…ˆæ·»åŠ ç©ºè¡Œ
            if not is_first_news:
                self.document.add_paragraph()
            
            # æ·»åŠ æ ‡é¢˜ï¼ˆä½¿ç”¨è‡ªå®šä¹‰æ ‡é¢˜æ ·å¼ï¼‰
            title_para = self.document.add_paragraph(style='ITHomeTitle')
            title_run = title_para.add_run(title)
            
            # æ·»åŠ å…ƒä¿¡æ¯ï¼ˆä½¿ç”¨æ­£æ–‡æ ·å¼ï¼‰
            meta_info = []
            if author:
                meta_info.append(f"ä½œè€…: {author}")
            if postdate:
                simple_date = postdate.split(' ')[0] if ' ' in postdate else postdate[:10]
                meta_info.append(f"æ—¶é—´: {simple_date}")
            
            if meta_info:
                meta_para = self.document.add_paragraph()
                meta_run = meta_para.add_run(" | ".join(meta_info))
            
            # æ·»åŠ å†…å®¹ï¼ˆä½¿ç”¨æ­£æ–‡æ ·å¼ï¼‰
            if full_content:
                formatted_content = self.format_content(full_content)
                for para in formatted_content.split('\n\n'):
                    if para.strip():
                        content_para = self.document.add_paragraph()
                        content_run = content_para.add_run(para.strip())
            
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡ç« åˆ°æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def generate_newspaper(self, total_articles=30, output_filename=None, max_retry_rounds=3):
        """ç”ŸæˆæŠ¥çº¸"""
        logger.info("ğŸš€ ITä¹‹å®¶æŠ¥çº¸ç”Ÿæˆå™¨ï¼ˆæ ‡å‡†æ ·å¼ç‰ˆï¼‰å¯åŠ¨")
        
        # åˆ›å»ºæ–‡æ¡£æ ‡é¢˜ï¼ˆä½¿ç”¨æ­£æ–‡æ ·å¼ï¼‰
        title_para = self.document.add_paragraph()
        title_run = title_para.add_run(f'ITä¹‹å®¶æŠ¥çº¸ - {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}')
        title_run.bold = True
        
        info_para = self.document.add_paragraph()
        info_run = info_para.add_run(f'ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        # è·å–æ–°é—»åˆ—è¡¨
        logger.info("ğŸ“¡ å¼€å§‹è·å–æ–°é—»åˆ—è¡¨...")
        all_news = self.get_multiple_pages(total_articles)
        
        if not all_news:
            logger.error("âŒ æœªèƒ½è·å–åˆ°ä»»ä½•æ–°é—»")
            return False
        
        logger.info(f"âœ… æˆåŠŸæ”¶é›† {len(all_news)} æ¡æ–°é—»")
        
        # åˆ†æ‰¹å¤„ç†æ–°é—»
        all_processed_news = []
        batch_count = (len(all_news) + self.batch_size - 1) // self.batch_size
        
        for i in range(batch_count):
            start_idx = i * self.batch_size
            end_idx = min((i + 1) * self.batch_size, len(all_news))
            batch = all_news[start_idx:end_idx]
            
            logger.info(f"å¤„ç†ç¬¬ {i + 1}/{batch_count} æ‰¹æ–°é—» ({len(batch)} ç¯‡)...")
            
            batch_results = self.process_news_batch(batch)
            all_processed_news.extend(batch_results)
            
           # if i < batch_count - 1:
                #delay = random.uniform(2, 5)
                #logger.info(f"æ‰¹æ¬¡é—´å»¶è¿Ÿ {delay:.2f} ç§’...")
               # time.sleep(delay)
        
        # é‡è¯•å¤±è´¥çš„æ–°é—»
        for retry_round in range(max_retry_rounds):
            if not self.failed_news_ids:
                break
                
            logger.info(f"ç¬¬ {retry_round + 1} è½®é‡è¯•å¼€å§‹...")
            retry_results = self.retry_failed_news()
            all_processed_news.extend(retry_results)
            
            if self.failed_news_ids:
                logger.warning(f"ç¬¬ {retry_round + 1} è½®é‡è¯•åä»æœ‰ {len(self.failed_news_ids)} ç¯‡å¤±è´¥")
        
        # æ·»åŠ åˆ°æ–‡æ¡£
        success_count = 0
        for i, (news, content_data) in enumerate(all_processed_news):
            if self.add_news_to_document(news, content_data, is_first_news=(i == 0)):
                success_count += 1
        
        # ä¿å­˜æ–‡æ¡£
        if not output_filename:
            output_filename = f"ITä¹‹å®¶æŠ¥çº¸_æ ‡å‡†æ ·å¼_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
        
        try:
            self.document.save(output_filename)
            logger.info(f"ğŸ‰ æŠ¥çº¸ç”Ÿæˆå®Œæˆï¼")
            logger.info(f"ğŸ“ æ–‡ä»¶: {output_filename}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡: {success_count}/{len(all_processed_news)} ç¯‡æ–‡ç« å¤„ç†æˆåŠŸ")
            
            if self.failed_news_ids:
                logger.warning(f"âš ï¸ ä»æœ‰ {len(self.failed_news_ids)} ç¯‡æ–‡ç« å¤±è´¥: {self.failed_news_ids}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False

def main():
    printer = ITHomePrinterWithStyles()
    
    print("=" * 60)
    print("     ITä¹‹å®¶æŠ¥çº¸ç”Ÿæˆå™¨ï¼ˆæ ‡å‡†æ ·å¼ç‰ˆï¼‰")
    print("=" * 60)
    print("ä¸¥æ ¼æŒ‰ç…§è§„å®šæ ¼å¼ç”Ÿæˆ:")
    print("  â€¢ æ ‡é¢˜: Microsoft YaHei UI Light, 11ç£…, å›ºå®šè¡Œè·13ç£…")
    print("  â€¢ æ­£æ–‡: æ–¹æ­£ä¹¦å®‹_GB18030/Times New Roman, 9ç£…, å›ºå®šè¡Œè·9ç£…")
    print("  â€¢ æ®µè½é—´è·: æ— é—´éš”")
    print("  â€¢ æ–°é—»é—´: ç©ºä¸€è¡Œ")
    print()
    
    try:
        total = input("è¯·è¾“å…¥è¦ç”Ÿæˆçš„æ–°é—»æ€»æ•° (é»˜è®¤30): ").strip()
        total_articles = int(total) if total.isdigit() else 30
        
        retry_rounds = input("è¯·è¾“å…¥æœ€å¤§é‡è¯•è½®æ¬¡ (é»˜è®¤3): ").strip()
        max_retry_rounds = int(retry_rounds) if retry_rounds.isdigit() else 3
        
        filename = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶å (é»˜è®¤è‡ªåŠ¨ç”Ÿæˆ): ").strip()
        filename = filename if filename else None
        
        print("\nå¼€å§‹ç”ŸæˆæŠ¥çº¸...")
        success = printer.generate_newspaper(total_articles, filename, max_retry_rounds)
        
        if success:
            print("\nâœ… ç¨‹åºæ‰§è¡ŒæˆåŠŸï¼")
            print("ğŸ“‹ æ ¼å¼è¯´æ˜:")
            print("   - æ ‡é¢˜: Microsoft YaHei UI Light, 11ç£…")
            print("   - æ­£æ–‡: æ–¹æ­£ä¹¦å®‹_GB18030/Times New Roman, 9ç£…")
            print("   - è¡Œè·: æ ‡é¢˜13ç£…ï¼Œæ­£æ–‡9ç£…")
            print("   - æ®µè½: æ— é—´éš”ï¼Œæ–°é—»é—´ç©ºä¸€è¡Œ")
        else:
            print("\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()
```
æˆ‘æ­£åœ¨è€ƒè™‘å°†å…¶ä¸Šä¼ è‡³GitHubã€‚æ¬¢è¿å„ä½è®¿é—®ã€‚